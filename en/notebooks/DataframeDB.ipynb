{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataframeBD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-vde5UCQRkQ"
      },
      "source": [
        "# Dataframes as databases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9He81AacH7Dk"
      },
      "source": [
        "Pandas dataframes offer different ways to query data. In some cases, these queries can become as elaborate as in traditional databases. In this notebook, we will see how to make simple queries to a dataset loaded from the internet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6iF2fKerEkf",
        "colab_type": "text"
      },
      "source": [
        "## Loading data from the internet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v80WmoYDrJec",
        "colab_type": "text"
      },
      "source": [
        "There are several ways to work with data loaded from the internet. Here, we will download the dataset using a Linux tool and load it into Pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MyR5JpdlW4Oq"
      },
      "source": [
        "### Downloading a dataset with `wget`\n",
        "\n",
        "Running a notebook on Colab is done on a computer on Google's infrastructure. Google computers use the Linux operating system and we can take advantage of that when a Linux program can help us. An example is the program ``wget``, which downloads the URL we provide. To run a Linux program on Colab, we have to do this via code cells, using Linux terminal commands beginning with the symbol ``!`` \n",
        "\n",
        "In this case, I used the ``wget`` to download a dataset from the UFRN open data portal that contains the incoming students in 2019:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OxJWg_znp9sr",
        "colab": {}
      },
      "source": [
        "!wget http://dados.ufrn.br/dataset/554c2d41-cfce-4278-93c6-eb9aa49c5d16/resource/a55aef81-e094-4267-8643-f283524e3dd7/download/discentes-2019.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uGNACj0msDF4"
      },
      "source": [
        "The file ``discentes-2019.csv`` should appear in the file list on the left side of the screen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTVqKyowrqbP",
        "colab_type": "text"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g0MCekkrrku",
        "colab_type": "text"
      },
      "source": [
        "Let's upload the file as a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gwSjQx6bvTCM",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('discentes-2019.csv', sep=';')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cxMtfVo6sqgl"
      },
      "source": [
        "In case you have any questions, let's review the code above:\n",
        "\n",
        " - ```python\n",
        " import pandas as pd\n",
        " ```\n",
        " We imported Pandas and called it ``pd``:\n",
        " ```python\n",
        "data = pd.read_csv('discentes-2019.csv', sep=';')\n",
        " ```\n",
        " - As we use a name for Pandas, all of its commands will be referenced using that name (ex.: ``pd.read_csv()``).\n",
        " - We inform the character that is used in the dataset as a feature delimiter using the option ``sep=';'`` (normally Pandas can detect this automatically, but in Brazilian datasets it often fails).\n",
        " ```python\n",
        " data.head()\n",
        " ```\n",
        " We visualize the first samples of the dataset with the method ``head()``.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0bLccn8pwD8o"
      },
      "source": [
        "## Querying a dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C74nFblQX1n7",
        "colab_type": "text"
      },
      "source": [
        "Well, we already have our dataframe ready for querying. The simplest forms of querying are **indexing** and **slicing**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmR9a9rPX3Ox",
        "colab_type": "text"
      },
      "source": [
        "### Indexing a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2irpE0zsX4j4",
        "colab_type": "text"
      },
      "source": [
        "Queries on a Pandas dataframe are based from **indices**. The main index on a dataframe are the columns, which represent the features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EPanQZfunULU",
        "colab": {}
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP3Sh9yCYiiv",
        "colab_type": "text"
      },
      "source": [
        "This means that we can access any of these dataframe columns using the notations `data['column_name']` and `data.column_name`. Let's first translate the feature names, since this dataframe is provided in Brazilian Portuguese. Before we do that, we need to understand the meaning of each feature. We do that using a [data dictionary](http://dados.ufrn.br/dataset/554c2d41-cfce-4278-93c6-eb9aa49c5d16/resource/b5144c99-81f3-4cfc-8938-18adb81ae3c0/download/discentesdicionario.pdf), where we see what each feature means."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCAWlNKAYh9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.columns = [\n",
        "                \"id\", \n",
        "                \"student_name\",\n",
        "                \"gender\",\n",
        "                \"start_year\",\n",
        "                \"start_semester\",\n",
        "                \"start_type\",\n",
        "                \"student_type\",\n",
        "                \"status\",\n",
        "                \"level_acronym\",\n",
        "                \"level\",\n",
        "                \"course_id\",\n",
        "                \"course_name\",\n",
        "                \"course_type\",\n",
        "                \"unit_id\",\n",
        "                \"unit_name\",\n",
        "                \"main_unit_id\",\n",
        "                \"main_unit_id\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QQkfJXoWHJ18"
      },
      "source": [
        " As each column is considered a series (object of type `Series`), we can use the methods of that type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PWnsq32eHJTB",
        "colab": {}
      },
      "source": [
        "data[\"student_name\"].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PKFVIl4uJO_w",
        "colab": {}
      },
      "source": [
        "data.unit_name.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MuP5PPjsJY4p"
      },
      "source": [
        "The data in a series is also indexed. We can access them individually using the notation `series[row_number]`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kiTFTNURKj1y",
        "colab": {}
      },
      "source": [
        "student_names = data[\"student_name\"]\n",
        "student_names[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FXpX4DS1LWCw",
        "colab": {}
      },
      "source": [
        "data[\"student_name\"][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HcZGxZm1LiXQ",
        "colab": {}
      },
      "source": [
        "data.unit_name[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuONpN_9ZO2V",
        "colab_type": "text"
      },
      "source": [
        "To make our analysis more meaningful yet simple, we will discard a few features and translate another.\n",
        "\n",
        "*   We can drop features using the method `drop()`, informing the feature list, and specifying that we refer to columns (`axis=1`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNC2RJU9ZuKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop([\"student_type\", \"level_acronym\", \"level\", \"course_type\"], axis=1)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j0WnlRZbofa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC5v0QvQbJZQ",
        "colab_type": "text"
      },
      "source": [
        "*   We can translate feature values if they are categorical. Changing a feature type do categorical saves memory space, so you should that even when translating is not an issue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ZQFijxcIVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"status\"] = data[\"status\"].astype(\"category\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv6V4qEfcz6y",
        "colab_type": "text"
      },
      "source": [
        "To translate a feature, we first list its existing values. We do that using the method `unique()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcsgBMx8ZcVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"status\"].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJQRoi-ndrnX",
        "colab_type": "text"
      },
      "source": [
        "To rename categories, we use the `rename_categories` method provided for categorical values, where we inform a list of novel category names in the same order returned by `unique`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icyoOMLub6Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"status\"] = data[\"status\"].cat.rename_categories([\"CANCELLED\", \"ACTIVE\", \"SUSPENDED\", \"FINISHED\", \"REGISTERED\", \"ACTIVE - GRADUATING\", \"DEFENDED\"])\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu_MPzbiepQr",
        "colab_type": "text"
      },
      "source": [
        "Note that we could translate other features using the same approach, but that would exceed the scope of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdsTS3pLdRoc",
        "colab_type": "text"
      },
      "source": [
        "#### The `loc` and `iloc` methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zd8LWkveyWBv"
      },
      "source": [
        "It is also possible to directly access the data using the methods `loc` and `iloc`:\n",
        "- Referring to columns by their names, using the notation `data.loc[row, column_name]`\n",
        ":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WgePGZkWNOU1",
        "colab": {}
      },
      "source": [
        "data.loc[0, \"student_name\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWl7e570OUP0"
      },
      "source": [
        "- Referring to columns by their position in the column index, using the notation `data.iloc[row, column_index]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T7Gq23b2Nohl",
        "colab": {}
      },
      "source": [
        "data.iloc[0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BcDrpBu1Ph04"
      },
      "source": [
        "Note that the indexes are counted from the number 0. Since `\"student_name\"` is the second column, we use index 1 to access it.\n",
        "\n",
        "The methods `loc` and `iloc` they also accept that you provide a list of indexes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7QUL-EOQQn2o",
        "colab": {}
      },
      "source": [
        "data.loc[0, [\"student_name\",\"course_name\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p8oN5MMZRBwi",
        "colab": {}
      },
      "source": [
        "data.iloc[[1,3,7], 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hjtzZhzlP-ku"
      },
      "source": [
        "### Slicing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iN1qf9NgNpVN"
      },
      "source": [
        "In most of the cases we're only interested in a particular subset of the data containing some continuous columns/rows. Selecting that subset can be done by using these slicing operations:\n",
        "- Slicing by rows, using `data.loc[row_start:row_end, column_name]`:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJPtTJxqDmTD",
        "colab": {}
      },
      "source": [
        "data.loc[0:500,'student_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tETV_5sCOcoQ"
      },
      "source": [
        "* By rows and columns simultaneously  based on their positions in the dataframe, using `data.iloc[row_start:row_end, column_start:column_end]`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X716AoGBDvcN",
        "colab": {}
      },
      "source": [
        "data.iloc[0:5, 5:8]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PqlltwoMOqsv"
      },
      "source": [
        "It's important to notice that slicing operations in Python usually includes the element located by the first index, but it doesn't include the element located by the second index.  This means  that when selecting multiple columns or multiple rows in this manner, you need to remember that in your selection the rows/columns selected will run from the first number to one minus the second number. Because of this, the example `data.iloc[0:5, 5:8]` returns 5 rows and 3 columns.\n",
        "\n",
        "The `loc` method is an exception: it also includes the row referenced by the second index. This is why the example `data.loc[0:500,'nome_discente']` returns 501 rows. You can also slice by columns in `loc` method, but this has to be done by the  columns labels. This is probably the reason why the second element in the index is also included."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xt4OTMXsPGrH",
        "colab": {}
      },
      "source": [
        "data.loc[0:500, 'student_name':'start_year']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zK2I__X1VaCz"
      },
      "source": [
        "## Queries just like those done in database development\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7nGWbGXrVdUz"
      },
      "source": [
        "The indexing and slicing operations are inherent to the Python language and  that's why they are implemented in Pandas.\n",
        "\n",
        "Partially they help transforming **selection** and **projection** into operations, both common in databases:\n",
        "- **Selection**: choosing a subset of samples\n",
        "- **Projection**: choosing a subset of features\n",
        "\n",
        "Pandas `DataFrame` provides more methods to these type of queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yr8LpSswZ_HV"
      },
      "source": [
        "#### Searching by the name of the features\n",
        "\n",
        "The method **filter()** chooses a subset of features based on its name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FzTKAWMsd_U4",
        "colab": {}
      },
      "source": [
        "data.filter(like='start')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vn1YdnXPXOjC"
      },
      "source": [
        "The result of the method **filter** is a new `DataFrame` that can be associated to a new name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cdBjaM_RXawY",
        "colab": {}
      },
      "source": [
        "start_date = data.filter(like='start')\n",
        "start_date.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I0fb6cKPL-wL"
      },
      "source": [
        "### Searching for conditions\n",
        "\n",
        "Another way to filter dataframes is through **conditions**. To that end, we use the method `query('condition')`, where `condition` is a logical expression from Python. For example, we will choose only the samples for which **start_type** equals **REINGRESSO SEGUNDO CICLO**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q0oc1e_PCDii",
        "colab": {}
      },
      "source": [
        "data.query(\"start_type == 'REINGRESSO SEGUNDO CICLO'\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OY0VDG5_jiQv"
      },
      "source": [
        "Letâ€™s discuss the example above:\n",
        "* `start_type` is a `Series` (column) from the `DataFrame` that we call `data` \n",
        "* We compare each value in this series with the value `'REINGRESSO SEGUNDO CICLO'` using the equality operator `==`\n",
        "```python\n",
        "data.query(\"start_type == 'REINGRESSO SEGUNDO CICLO'\")\n",
        "```\n",
        "We choose only the samples that satisfy that condition. \n",
        "\n",
        "Note that we can also use names to reference the returned `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0mwwuJ7Xkd2g",
        "colab": {}
      },
      "source": [
        "data_second_cycle = data.query(\"start_type == 'REINGRESSO SEGUNDO CICLO'\")\n",
        "data_second_cycle.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l5S3EdmLp1F8"
      },
      "source": [
        "#### Conditions and comparison operators\n",
        "\n",
        "In the example above, we use the equality operator. Note that itâ€™s different to use `==` (comparison of equality) and `=` (association of a name to an object). Python offers more comparison operators:\n",
        "\n",
        "| Symbol | Meaning |\n",
        "|:----:|---|\n",
        "| == | Equal to |\n",
        "| !=  | Not equal |\n",
        "| < | Less than |\n",
        "| > | Greater than |\n",
        "| <=  | Less than or equal to |\n",
        "| >=  | Greater than or equal to |\n",
        "\n",
        "It is also important to observe that the operators less than/greater than (or equal to) usually are applied to numeric data. For non-numeric data, we can use the operator `in`. Letâ€™s choose only the observations whose status is \"CANCELLED\" or \"SUSPENDED\":\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qh-TQoNbsXNC",
        "colab": {}
      },
      "source": [
        "selected_status = [\"CANCELLED\", \"SUSPENDED\"]\n",
        "data_status = data.query(f\"status in {selected_status}\")\n",
        "data_status.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMabVSaXE0Rp",
        "colab_type": "text"
      },
      "source": [
        "Letâ€™s discuss the example above:\n",
        "* `selected_status` is a list with the statuses that we wish to filter. \n",
        "* We filter the dataframe `data` indicating that we want only the samples whose status value is specified on the list `selected_status`.\n",
        "```python\n",
        "data.query(f\"status in {status_desejados}\")\n",
        "```\n",
        "Note that we use a Python resource called `f-strings`, that allows to convert text objects specified between curly braces (an `f-string` always starts with an `f` before quotation marks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FLLC_2stfihh"
      },
      "source": [
        "#### Conditions and Logical Operators\n",
        "We can also use more complex conditions, using **logical operators**. We are going to restrict the query above a little more. In addition to **start_type** having value **REINGRESSO SEGUNDO CICLO**, **course_name** has value **ENGENHARIA DE SOFTWARE**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y25iRIQnldzG",
        "colab": {}
      },
      "source": [
        "condition_second_cycle = \"start_type == 'REINGRESSO SEGUNDO CICLO'\"\n",
        "condition_software_engineering = \"course_name == 'ENGENHARIA DE SOFTWARE'\"\n",
        "data_second_SE = data.query(f\"{condition_second_cycle} and {condition_software_engineering}\")\n",
        "data_second_SE.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6gBoCgGdl33r"
      },
      "source": [
        "Reviewing the code above:\n",
        "* ```python\n",
        "condition_second_cycle = \"start_type == 'REINGRESSO SEGUNDO CICLO'\"\n",
        "````\n",
        "Condition to choose only new entrants through second cycle re-entry.\n",
        "```python\n",
        "condition_software_engineering = \"course_name == 'ENGENHARIA DE SOFTWARE'\"\n",
        "```\n",
        "Condition to choose only those entering the software engineering course.\n",
        "```python\n",
        "data_second_SE = data.query(f\"{condition_second_cycle} and {condition_software_engineering}\")\n",
        "```\n",
        "Combining the two conditions through the `and` operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_-dAt2lgodAi"
      },
      "source": [
        "#### Other logical operators\n",
        "\n",
        "In addition to the `and` operator, Pandas also provides the` or` operator. While the `and` operator chooses the sample only if both conditions are true, the `or` will choose it if one of the conditions is satisfied. Following this definition, what does the example below do?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C8yVonNefiqB",
        "colab": {}
      },
      "source": [
        "condition_second_cycle = \"start_type == 'REINGRESSO SEGUNDO CICLO'\"\n",
        "condition_software_engineering = \"course_name == 'ENGENHARIA DE SOFTWARE'\"\n",
        "condition_computer_science = \"course_name == 'CIÃŠNCIA DA COMPUTAÃ‡ÃƒO'\"\n",
        "condition_unit = f\"{condition_computer_science} or {condition_software_engineering}\"\n",
        "condition_second_unit = data.query(f\"{condition_second_cycle} and {condition_unit}\")\n",
        "condition_second_unit.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lYIp5ZOcomNe"
      },
      "source": [
        "Reviewing the code above:\n",
        "* ```python\n",
        "condition_second_cycle = \"start_type == 'REINGRESSO SEGUNDO CICLO'\"\n",
        "````\n",
        "Condition to choose only new entrants through second cycle re-entry.\n",
        "```python\n",
        "condition_software_engineering = \"course_name == 'ENGENHARIA DE SOFTWARE'\"\n",
        "```\n",
        "Condition to choose only those entering the software engineering course.\n",
        "```python\n",
        "condition_computer_science = \"course_name == 'CIÃŠNCIA DA COMPUTAÃ‡ÃƒO'\"\n",
        "```\n",
        "Condition to choose only those entering the computer science course.\n",
        "```python\n",
        "condition_unit = f\"{condition_computer_science} or {condition_software_engineering}\"\n",
        "```\n",
        "Combining the two conditions using the `or` operator.\n",
        "```python\n",
        "condition_second_unit = data.query(f\"{condition_second_cycle} and {condition_unit}\")\n",
        "```\n",
        "Combining the two conditions using the `and` operator.\n",
        "\n",
        "Note that we used the `or` operator when we could have used the` in` operator, which is more readable. In general, we adopt the `or` operator when conditions involve different features, instead of different values for the same feature.\n",
        "\n",
        "Finally, the operator `not` is used to invert a condition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VM2AENbdpel7",
        "colab": {}
      },
      "source": [
        "data_direct_start = data.query(f\"not {condition_second_cycle}\")\n",
        "data_direct_start.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N4ij0OwfuPUu"
      },
      "source": [
        "* **Note**: complex logical expressions deserve specific research on the subject. Covering this topic in depth is beyond the scope of this notebook ðŸ™ƒ"
      ]
    }
  ]
}